{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Projeto Spark Code\n",
        "\n",
        "Esse projeto visa trazer informações do [Banco Central do Brasil](https://dadosabertos.bcb.gov.br/), e realizar estudos em cima disso.\n",
        "\n",
        "Utilizando ferramentas atualizadas e importantes no mercado de tecnologia.\n",
        "Entre elas:\n",
        "- Ngrok\n",
        "- Apache Spark\n",
        "- Google Colab\n",
        "- Google Drive\n",
        "- GCP \n",
        "\n",
        "### Documentações Utilizadas:\n",
        "\n",
        "[GCP para Big Data](https://cloud.google.com/architecture/build-a-data-lake-on-gcp?hl=pt-br#cloud-storage-as-data-lake)\n",
        "\n",
        "### Fontes Utilizadas:\n",
        "- [Indicador de Custo do Crédito - ICC - Crédito direcionado](https://dadosabertos.bcb.gov.br/dataset/25357-indicador-de-custo-do-credito---icc---credito-direcionado)\n",
        "\n",
        "  Conceito: Custo médio das operações de crédito que integram a carteira de empréstimos, financiamentos e arrendamento mercantil das instituições financeiras integrantes do Sistema Financeiro Nacional. Inclui todas as operações em aberto classificadas no ativo circulante, independente da data de contratação do crédito.\n",
        "\n",
        " **Fonte: Banco Central do Brasil – Departamento de Estatísticas**\n",
        "\n"
      ],
      "metadata": {
        "id": "m997LDPLVHMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurações"
      ],
      "metadata": {
        "id": "Z20THcaXVTXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instalar as dependências\n",
        "!apt-get update -qq\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "S5u4l5lZVW4G"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "rhNvdyEoVu5e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "b08jUIswVw5f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download e extração dos arquivos do ngrok\n",
        "\n",
        "Link de apoio: (https://dashboard.ngrok.com/get-started/setup)"
      ],
      "metadata": {
        "id": "pNRlhZPyXt5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-pZlPNIXsvx",
        "outputId": "a7680df4-2259-4e82-844d-446581885a41"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuração do Authtoken obtido no site do ngrok"
      ],
      "metadata": {
        "id": "UBO1Rm6jX9PL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok authtoken 2PsAql4UytDT4URhHVThKcBvwin_2PAPWHdDtoPoZRqRXi7bg')\n",
        "get_ipython().system_raw('./ngrok http 80 &')"
      ],
      "metadata": {
        "id": "-UTQaCRMYBZa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verificando se a autenticação e a porta funciona"
      ],
      "metadata": {
        "id": "BcwQKTKEYVZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -s http://localhost:4040/api/tunnels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNS9A9yxYZVH",
        "outputId": "ef50b129-18f8-49c6-a8bb-0271eebc345b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"tunnels\":[],\"uri\":\"/api/tunnels\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Realizando conexão com Google Drive"
      ],
      "metadata": {
        "id": "jFlDKtpDaZnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UsDE_GMma5IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sessão SparkSession"
      ],
      "metadata": {
        "id": "20TTH1VfXjoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uma SparkSession pode ser usada para criar DataFrames, registrar DataFrames como tabelas, executar comandos SQL sobre tabelas, armazenar tabelas em cache e ler arquivos em diferentes formatos."
      ],
      "metadata": {
        "id": "PVZt0-JSYzb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .master('local[*]') \\\n",
        "    .appName(\"Iniciando com Spark\") \\\n",
        "    .config('spark.ui.port', '80') \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "kk0xuyqbVzOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Realizando a leitura dos dados"
      ],
      "metadata": {
        "id": "Ey6649LAaUWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para arquivos .zip"
      ],
      "metadata": {
        "id": "fJOLr_NHUv9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import zipfile\n",
        "\n",
        "# zipfile.ZipFile('path_arquivo', 'r').extractall('path_destino')"
      ],
      "metadata": {
        "id": "uqHzn_8dfYCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leitura de CSV"
      ],
      "metadata": {
        "id": "Lyo3x0X0WAKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/data_sources/banco_central/credito_direcionado/indicador_custo.csv'\n",
        "df = spark.read.csv(path, sep=';', inferSchema=True)"
      ],
      "metadata": {
        "id": "AqAWnJp2Vmuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VztbUJnfY27X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}